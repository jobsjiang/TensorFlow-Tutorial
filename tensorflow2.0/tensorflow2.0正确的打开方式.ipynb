{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s/UJx0KJi15nCAXmYGyGEtIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa1ba85a20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa1b7c2c50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train[...,tf.newaxis]\n",
    "x_test = x_test[...,tf.newaxis]\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,213,002\n",
      "Trainable params: 3,213,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 高级API搭建模型+高级API训练模型\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.8697\n",
      "Epoch 00001: val_loss improved from inf to 0.29203, saving model to ../../dataset\\model.weights.best.hdf5\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.3637 - accuracy: 0.8697 - val_loss: 0.2920 - val_accuracy: 0.8920\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9153\n",
      "Epoch 00002: val_loss improved from 0.29203 to 0.28417, saving model to ../../dataset\\model.weights.best.hdf5\n",
      "1875/1875 [==============================] - 50s 26ms/step - loss: 0.2336 - accuracy: 0.9153 - val_loss: 0.2842 - val_accuracy: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4c65ccef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='../../dataset/model.weights.best.hdf5',verbose=1,save_best_only=True)\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=2,validation_data=(x_test,y_test),callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 低级API搭建模型+高级API训练模型\n",
    "class FashionNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FashionNet,self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32,3,activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(128,activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(10,activation='softmax')\n",
    "    def call(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        out = self.d2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8640\n",
      "Epoch 00001: val_loss improved from inf to 0.31390, saving model to ../../dataset\\model.weights.best.hdf5\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 0.3786 - accuracy: 0.8640 - val_loss: 0.3139 - val_accuracy: 0.8863\n",
      "Epoch 2/2\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9078\n",
      "Epoch 00002: val_loss improved from 0.31390 to 0.27592, saving model to ../../dataset\\model.weights.best.hdf5\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.2497 - accuracy: 0.9078 - val_loss: 0.2759 - val_accuracy: 0.9004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b4c4465e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FashionNet()\n",
    "model.build(input_shape=(None,28,28,1))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='../../dataset/model.weights.best.hdf5',verbose=1,save_best_only=True)\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=2,validation_data=(x_test,y_test),callbacks=[checkpointer])keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 低级API搭建模型+低级API训练模型\n",
    "class FashionNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FashionNet,self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32,3,activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(128,activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(10,activation='softmax')\n",
    "    def call(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        out = self.d2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1102 15:10:32.501978  4812 base_layer.py:2377] Layer fashion_net_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3820117115974426, Accuracy: 86.22666931152344, Test Loss: 0.28103160858154297, Test Accuracy: 89.39666748046875\n",
      "Epoch 2, Loss: 0.2455371767282486, Accuracy: 90.97166442871094, Test Loss: 0.20824266970157623, Test Accuracy: 92.21666717529297\n",
      "Epoch 3, Loss: 0.18938180804252625, Accuracy: 93.13333892822266, Test Loss: 0.1741063892841339, Test Accuracy: 93.63500213623047\n",
      "Epoch 4, Loss: 0.14432667195796967, Accuracy: 94.85832977294922, Test Loss: 0.13567322492599487, Test Accuracy: 94.99666595458984\n",
      "Epoch 5, Loss: 0.1090964525938034, Accuracy: 96.14666748046875, Test Loss: 0.10261349380016327, Test Accuracy: 96.14166259765625\n"
     ]
    }
   ],
   "source": [
    "model = FashionNet()\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_ds = train_ds.batch(batch_size=32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = test_ds.batch(batch_size=32)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "def train_step(images,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels,predictions)\n",
    "        gradients = tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels,predictions)\n",
    "def test_step(images,labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels,predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels,predictions)\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    for images,labels in train_ds:\n",
    "        train_step(images,labels)\n",
    "    for test_images,test_labels in test_ds:\n",
    "        test_step(test_images,test_labels)\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,train_loss.result(),train_accuracy.result()*100,test_loss.result(),test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,213,002\n",
      "Trainable params: 3,213,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 高级API搭建模型+低级API训练模型\n",
    "inputs = tf.keras.layers.Input(shape=(28,28,1))\n",
    "conv2d = tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu')(inputs)\n",
    "flat = tf.keras.layers.Flatten()(conv2d)\n",
    "dense = tf.keras.layers.Dense(128,activation='relu')(flat)\n",
    "outputs = tf.keras.layers.Dense(10,activation='softmax')(dense)\n",
    "model = tf.keras.models.Model(inputs=inputs,outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.37241584062576294, Accuracy: 86.58333587646484, Test Loss: 0.259939044713974, Test Accuracy: 90.27333068847656\n",
      "Epoch 2, Loss: 0.24234150350093842, Accuracy: 91.02999877929688, Test Loss: 0.19628146290779114, Test Accuracy: 92.68000030517578\n",
      "Epoch 3, Loss: 0.1828906387090683, Accuracy: 93.36166381835938, Test Loss: 0.15902476012706757, Test Accuracy: 94.05333709716797\n",
      "Epoch 4, Loss: 0.13792045414447784, Accuracy: 95.02166748046875, Test Loss: 0.1326255202293396, Test Accuracy: 94.97333526611328\n",
      "Epoch 5, Loss: 0.10284900665283203, Accuracy: 96.28499603271484, Test Loss: 0.12878020107746124, Test Accuracy: 95.33666229248047\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_ds = train_ds.batch(batch_size=32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = test_ds.batch(batch_size=32)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "def train_step(images,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels,predictions)\n",
    "        gradients = tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels,predictions)\n",
    "def test_step(images,labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels,predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels,predictions)\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    for images,labels in train_ds:\n",
    "        train_step(images,labels)\n",
    "    for test_images,test_labels in test_ds:\n",
    "        test_step(test_images,test_labels)\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,train_loss.result(),train_accuracy.result()*100,test_loss.result(),test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-tf2]",
   "language": "python",
   "name": "conda-env-anaconda3-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
